{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55e0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_query = 'inurl:linkedin.com/in \"enterprise\" \"@gmail\" \"France\"'\n",
    "# bing_query = 'site:linkedin.com/in \"enterprise\" \"@gmail.com\" \"France\"'\n",
    "\n",
    "# encoded_query = urllib.parse.quote_plus(google_query)\n",
    "# google_url = f\"https://www.google.com/search?q={encoded_query}&num={10}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d35281bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize brower\n",
    "# driver = webdriver.Chrome()\n",
    "\n",
    "# # open google search\n",
    "# driver.maximize_window()\n",
    "# driver.get(\"https://www.google.com/\")\n",
    "# time.sleep(3)\n",
    "\n",
    "# # Locate Element Search Bar\n",
    "# search_bar_xpath = '//*[@id=\"APjFqb\"]'\n",
    "# results_xpath = '//*[@id=\"rso\"]'\n",
    "# search_bar = driver.find_element(By.XPATH, search_bar_xpath)\n",
    "\n",
    "# # Enter the search query\n",
    "# search_bar.send_keys(google_query)\n",
    "# time.sleep(2)\n",
    "\n",
    "# # Click the search button\n",
    "# search_bar.send_keys(Keys.RETURN)\n",
    "# # time.sleep(10)\n",
    "\n",
    "# results = driver.find_element(By.XPATH, results_xpath)\n",
    "# links = results.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "# for link in links:\n",
    "#     href = link.get_attribute(\"href\")\n",
    "#     if href:\n",
    "#         print(href)\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "640626b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Found: https://fr.linkedin.com/in/hadil-tissent-50351a221\n",
      "[3] Found: https://cg.linkedin.com/in/esther-nloga-1a36b866\n",
      "[4] Found: https://hu.linkedin.com/in/marcellcsomor\n",
      "[5] Found: https://ae.linkedin.com/in/aliasghar-rostami\n",
      "[6] Found: https://uk.linkedin.com/in/andrew-mylan-1958a43b\n",
      "[7] Found: https://uk.linkedin.com/in/kirsty-reid-smsts-cism-36778b14\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "def scrape_google_links(query: str, num_results: int = 10, output_csv: str = \"results.csv\"):\n",
    "    \n",
    "    # Set up Google search URL\n",
    "    # encoded_query = urllib.parse.quote_plus(query)\n",
    "    # google_url = f\"search?q={encoded_query}&num={num_results}\"\n",
    "\n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.google.com\")\n",
    "\n",
    "    # Accept cookies if prompted\n",
    "    try:\n",
    "        consent_button = driver.find_element(By.XPATH, '//button[contains(text(), \"Accept all\")]')\n",
    "        consent_button.click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Enter the search query\n",
    "    search_box = driver.find_element(By.NAME, \"q\")\n",
    "    search_box.send_keys(query + Keys.RETURN)\n",
    "\n",
    "    # Wait for results to load (adjust time if needed)\n",
    "    time.sleep(25)\n",
    "\n",
    "    # Base XPath pattern (index placeholder)\n",
    "    xpath_pattern = '/html/body/div[3]/div/div[12]/div/div[2]/div[2]/div/div/div[{}]/div/div/div[1]/div/div[2]/div/div/span/a'\n",
    "\n",
    "    found_links = []\n",
    "\n",
    "    for i in range(1, num_results + 1):\n",
    "        xpath = xpath_pattern.format(i)\n",
    "        try:\n",
    "            link_element = driver.find_element(By.XPATH, xpath)\n",
    "            href = link_element.get_attribute(\"href\")\n",
    "            if href:\n",
    "                print(f\"[{i}] Found: {href}\")\n",
    "                found_links.append(href)\n",
    "            else:\n",
    "                pass\n",
    "                # print(f\"[{i}] Element found but href is empty.\")\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(f\"[{i}] Could not find link at XPath: {xpath}\")\n",
    "\n",
    "    driver.quit()\n",
    "    return found_links\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = 'inurl:linkedin.com/in \"enterprise\" \"@gmail\" \"France\"'\n",
    "    results = scrape_google_links(query, num_results=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fe01738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# import time\n",
    "\n",
    "# # Initialize the Chrome WebDriver\n",
    "# encoded_query = urllib.parse.quote_plus(google_query)\n",
    "# google_url = f\"https://www.google.com/search?q={encoded_query}&num={num_of_results}\"\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.get(\"https://www.google.com\")\n",
    "\n",
    "# # Accept cookies if needed (optional - depends on your region/settings)\n",
    "# try:\n",
    "#     consent_button = driver.find_element(By.XPATH, '//button[contains(text(), \"Accept all\")]')\n",
    "#     consent_button.click()\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# # Enter the search query\n",
    "# search_box = driver.find_element(By.NAME, \"q\")\n",
    "# search_query = 'inurl:linkedin.com/in \"enterprise\" \"@gmail\" \"France\"'\n",
    "# search_box.send_keys(search_query + Keys.RETURN)\n",
    "\n",
    "# # Wait for results to load\n",
    "# time.sleep(25)\n",
    "\n",
    "# # List of XPaths to extract\n",
    "# xpaths = [\n",
    "#     '/html/body/div[3]/div/div[12]/div/div[2]/div[2]/div/div/div[1]/div/div/div[1]/div/div[2]/div/div/span/a/h3',\n",
    "#     '/html/body/div[3]/div/div[12]/div/div[2]/div[2]/div/div/div[3]/div/div/div[1]/div/div[2]/div/div/span/a/h3',\n",
    "#     '/html/body/div[3]/div/div[12]/div/div[2]/div[2]/div/div/div[4]/div/div/div[1]/div/div[2]/div/div/span/a/h3'\n",
    "# ]\n",
    "\n",
    "# xpaths_url = [\n",
    "#     \"/html/body/div[3]/div/div[12]/div/div[2]/div[2]/div/div/div[1]/div/div/div[1]/div/div[2]/div/div/span/a\"\n",
    "# ]\n",
    "\n",
    "# # Extract and print the titles\n",
    "# for xpath in xpaths_url:\n",
    "#     try:\n",
    "#         element = driver.find_element(By.XPATH, xpath)\n",
    "#         href = element.get_attribute(\"href\")\n",
    "#         print(\"Found\", href)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not find element for xpath: {xpath} â€“ {str(e)}\")\n",
    "\n",
    "# # Optional: close the browser\n",
    "# driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
